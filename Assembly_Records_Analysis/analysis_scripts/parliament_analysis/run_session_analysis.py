#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
êµ­íšŒ íšŒì˜ë¡ OpenAI ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (RAG íŒŒì´í”„ë¼ì¸ í†µí•©)
"""

from __future__ import annotations

import os
import warnings
import json
from dataclasses import asdict
from typing import Any, Dict, List, Optional, Sequence, Tuple

import matplotlib.pyplot as plt
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI

from .data.db_client import SupabaseDBClient
from .data.embedding_client import EmbeddingClient
from .pipeline.utils import generate_analysis_version
from .pipeline.workflow import SessionAnalysisWorkflow
from .pipeline.persistence import persist_analysis_to_supabase
from .rag.chunker import RAGChunker
from .rag.vector_store import VectorStore

warnings.filterwarnings("ignore")

plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False

load_dotenv()


def create_openai_client() -> OpenAI:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return OpenAI(api_key=api_key)


def ensure_supabase_clients(
    openai_client: OpenAI,
) -> Optional[Tuple[SupabaseDBClient, EmbeddingClient, VectorStore, RAGChunker]]:
    if not os.getenv("SUPABASE_URL") or not (
        os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_API_KEY")
    ):
        return None

    db_client = SupabaseDBClient.from_env()
    embedding_client = EmbeddingClient(openai_client=openai_client)
    vector_store = VectorStore(db_client=db_client, embedding_client=embedding_client)
    chunker = RAGChunker()
    return db_client, embedding_client, vector_store, chunker


def create_visualizations(results: Dict[str, Any], session_name: str) -> None:
    """ë¶„ì„ ê²°ê³¼ ì‹œê°í™”."""
    print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")

    output_dir = "analysis_results"
    os.makedirs(output_dir, exist_ok=True)

    summary = results.get("session_summary")
    if summary and summary.get("key_issues"):
        fig, ax = plt.subplots(figsize=(12, 6))
        issues = [issue["issue"] for issue in summary["key_issues"]]
        importance_map = {"ë†’ìŒ": 3, "ì¤‘ê°„": 2, "ë‚®ìŒ": 1}
        importance_scores = [
            importance_map.get(issue.get("importance", "ì¤‘ê°„"), 2)
            for issue in summary["key_issues"]
        ]

        ax.barh(issues, importance_scores, color="steelblue")
        ax.set_xlabel("ì¤‘ìš”ë„", fontsize=12)
        ax.set_title(f"{session_name} í•µì‹¬ ì´ìŠˆ ì¤‘ìš”ë„", fontsize=14, fontweight="bold")
        ax.set_xlim(0, 4)
        plt.tight_layout()
        plt.savefig(
            os.path.join(output_dir, f"{session_name}_key_issues.png"),
            dpi=300,
            bbox_inches="tight",
        )
        plt.close()
        print("  âœ… í•µì‹¬ ì´ìŠˆ ì¤‘ìš”ë„ ì°¨íŠ¸ ìƒì„±")

    party_overview = summary.get("metadata", {}).get("party_positions_overview") if summary else None
    if party_overview:
        parties = list(party_overview.keys())
        if parties:
            fig, ax = plt.subplots(figsize=(10, 6))
            concerns_count = [
                len(party_overview[party].get("main_concerns", [])) for party in parties
            ]

            ax.bar(parties, concerns_count, color="coral")
            ax.set_ylabel("ì£¼ìš” ê´€ì‹¬ì‚¬ ìˆ˜", fontsize=12)
            ax.set_title(
                f"{session_name} ì •ë‹¹ë³„ ì£¼ìš” ê´€ì‹¬ì‚¬ (ì§ˆì˜-ì‘ë‹µ íšŒì˜)",
                fontsize=14,
                fontweight="bold",
            )
            plt.xticks(rotation=45, ha="right")
            plt.tight_layout()
            plt.savefig(
                os.path.join(output_dir, f"{session_name}_party_concerns.png"),
                dpi=300,
                bbox_inches="tight",
            )
            plt.close()
            print("  âœ… ì •ë‹¹ë³„ ê´€ì‹¬ì‚¬ ì°¨íŠ¸ ìƒì„±")

    qa = results.get("qa_analysis")
    if qa and qa.get("quality_distribution"):
        def _to_numeric(value: Any) -> float:
            if value is None:
                return 0.0
            if isinstance(value, (int, float)):
                return float(value)
            if isinstance(value, str):
                sanitized = value.strip().replace("%", "")
                if not sanitized:
                    return 0.0
                try:
                    return float(sanitized)
                except ValueError:
                    return 0.0
            return 0.0

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

        quality = qa["quality_distribution"]
        labels = ["ê³ í’ˆì§ˆ", "ì¤‘í’ˆì§ˆ", "ì €í’ˆì§ˆ"]
        sizes = [
            _to_numeric(quality.get("high")),
            _to_numeric(quality.get("medium")),
            _to_numeric(quality.get("low")),
        ]
        colors = ["#2ecc71", "#f39c12", "#e74c3c"]

        ax1.pie(sizes, labels=labels, colors=colors, autopct="%1.1f%%", startangle=90)
        ax1.set_title("ì‘ë‹µ í’ˆì§ˆ ë¶„í¬", fontsize=12, fontweight="bold")

        q_types = qa.get("question_types", {})
        if q_types:
            type_labels = list(q_types.keys())
            type_values = [_to_numeric(q_types.get(k)) for k in type_labels]

            ax2.bar(range(len(type_labels)), type_values, color="steelblue")
            ax2.set_xticks(range(len(type_labels)))
            ax2.set_xticklabels(["ì •ì±… ì§ˆì˜", "ì‚¬ì‹¤ í™•ì¸", "ë¹„íŒ ì§ˆì˜", "ì œì•ˆ ì§ˆì˜"], rotation=45, ha="right")
            ax2.set_ylabel("ë¹„ìœ¨ (%)", fontsize=12)
            ax2.set_title("ì§ˆë¬¸ ìœ í˜• ë¶„í¬", fontsize=12, fontweight="bold")

        plt.suptitle(f"{session_name} ì§ˆì˜-ì‘ë‹µ íš¨ê³¼ì„± ë¶„ì„", fontsize=14, fontweight="bold")
        plt.tight_layout()
        plt.savefig(
            os.path.join(output_dir, f"{session_name}_qa_quality.png"),
            dpi=300,
            bbox_inches="tight",
        )
        plt.close()
        print("  âœ… ì§ˆì˜-ì‘ë‹µ í’ˆì§ˆ ì°¨íŠ¸ ìƒì„±")

    print(f"ğŸ“Š ì‹œê°í™” ì™„ë£Œ: analysis_results/{session_name}_*.png")


def main(session_name: str = "ì œ415íšŒ") -> None:
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜."""
    print("=" * 60)
    print(f"{session_name} êµ­íšŒ íšŒì˜ë¡ OpenAI ì‹¬ì¸µ ë¶„ì„")
    print("=" * 60)

    openai_client = create_openai_client()
    workflow = SessionAnalysisWorkflow(openai_client=openai_client)

    print(f"ğŸ“Š {session_name} ë°ì´í„° ë¡œë”© ì¤‘...")
    df = workflow.load_session_data(session_name=session_name)
    print(f"âœ… ì´ {len(df):,}ê°œ ë°œì–¸ ë¡œë“œ ì™„ë£Œ")

    print("\nğŸ” ìµœì†Œ í•„í„°ë§ ìˆ˜í–‰ ì¤‘ (ë¬¸ë§¥ íŒë‹¨ì€ OpenAIê°€ ìˆ˜í–‰)...")
    quality_df = workflow.filter_quality_speeches(df)
    print("ğŸ“Š í•„í„°ë§ ê²°ê³¼:")
    print(f"  - ì „ì²´ ë°œì–¸: {len(df):,}ê°œ")
    print(f"  - ìœ íš¨ ë°œì–¸: {len(quality_df):,}ê°œ ({len(quality_df)/len(df)*100:.1f}%)")
    print("  âš ï¸ í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ ì œê±°: ë¬¸ë§¥ íŒë‹¨ì€ OpenAIê°€ ìˆ˜í–‰í•©ë‹ˆë‹¤")

    hash_digest = workflow.compute_dataframe_hash(df)
    analysis_version = generate_analysis_version()

    results: Dict[str, Any] = {
        "session_name": session_name,
        "total_speeches": len(df),
        "quality_speeches": len(quality_df),
        "analysis_timestamp": pd.Timestamp.now().isoformat(),
        "analysis_version": analysis_version,
        "hash_digest": hash_digest,
    }

    print("\n" + "=" * 60)
    print("1ë‹¨ê³„: íšŒì°¨ë³„ í•µì‹¬ ì´ìŠˆ ìš”ì•½")
    print("=" * 60)
    summary_payload = workflow.prepare_session_summary_payload(quality_df)
    session_summary = workflow.run_session_summary(session_name, payload=summary_payload)
    if session_summary:
        results["session_summary"] = asdict(session_summary)

    agenda_payloads = workflow.prepare_agenda_payloads(quality_df, top_agendas=3)
    party_analyses = workflow.run_party_positions(session_name, agenda_payloads=agenda_payloads)
    if party_analyses:
        results["party_positions"] = [asdict(analysis) for analysis in party_analyses]

    qa_pairs = workflow.prepare_qa_pairs(quality_df, session_name)
    if not qa_pairs:
        print("  âš ï¸ ì§ˆì˜-ì‘ë‹µ ìŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    qa_metrics = workflow.run_qa_analysis(session_name, qa_pairs=qa_pairs)
    if qa_metrics:
        results["qa_analysis"] = asdict(qa_metrics)

    output_dir = "analysis_results"
    os.makedirs(output_dir, exist_ok=True)
    json_path = os.path.join(output_dir, f"{session_name}_openai_analysis.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {json_path}")
    create_visualizations(results, session_name)

    supabase_clients = ensure_supabase_clients(openai_client)
    if supabase_clients:
        db_client, embedding_client, vector_store, chunker = supabase_clients
        print("\nâ˜ï¸ Supabaseì— ë¶„ì„ ê²°ê³¼ ë™ê¸°í™” ì¤‘...")
        persist_analysis_to_supabase(
            session_name=session_name,
            hash_digest=hash_digest,
            analysis_version=analysis_version,
            raw_df=df,
            quality_df=quality_df,
            session_summary=session_summary,
            party_analyses=party_analyses,
            qa_pairs=qa_pairs,
            qa_metrics=qa_metrics,
            db_client=db_client,
            embedding_client=embedding_client,
            vector_store=vector_store,
            chunker=chunker,
        )
        print("âœ… Supabase ë™ê¸°í™” ì™„ë£Œ")
    else:
        print("\nâ„¹ï¸ Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë¡œì»¬ JSON/ì‹œê°í™”ë§Œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    print("\n" + "=" * 60)
    print("ë¶„ì„ ì™„ë£Œ ìš”ì•½")
    print("=" * 60)
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {json_path}")
    print(f"ğŸ“Š ì´ ë°œì–¸ ìˆ˜: {len(df):,}ê°œ")
    print(f"âœ… í’ˆì§ˆ ë°œì–¸ ìˆ˜: {len(quality_df):,}ê°œ")

    if session_summary and session_summary.key_issues:
        print(f"\nğŸ” í•µì‹¬ ì´ìŠˆ: {len(session_summary.key_issues)}ê°œ")
        for issue in session_summary.key_issues[:3]:
            print(f"  - {issue.get('issue', 'N/A')} ({issue.get('importance', 'N/A')})")

    if party_analyses:
        print(f"\nğŸ“‹ ë¶„ì„ëœ ì•ˆê±´ ìˆ˜: {len(party_analyses)}ê°œ")

    if qa_metrics:
        print(f"\nğŸ’¬ ì§ˆì˜-ì‘ë‹µ ìŒ: {qa_metrics.total_qa_pairs}ê°œ")
        if qa_metrics.quality_distribution:
            print(f"  - ê³ í’ˆì§ˆ ì‘ë‹µ: {qa_metrics.quality_distribution.get('high', 0)}%")

    print("\nâœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


if __name__ == "__main__":
    main()

